import streamlit as st
import os
from openai import OpenAI
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer, util

# Load SBERT model
sbert_model = SentenceTransformer("all-MiniLM-L6-v2")

# Set OpenAI API Key in the environment
os.environ["OPENAI_API_KEY"] = st.secrets["api"]["key"]
client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY"),  # This is the default and can be omitted
)
# Sample FAQ database
faq_data = [
    {"question": "Quy trÃ¬nh tuyá»ƒn sinh nhÆ° tháº¿ nÃ o?", "answer": "Quy trÃ¬nh tuyá»ƒn sinh bao gá»“m ná»™p Ä‘Æ¡n, báº£ng Ä‘iá»ƒm vÃ  Ä‘Ã¡p á»©ng cÃ¡c tiÃªu chÃ­ Ä‘á»§ Ä‘iá»u kiá»‡n."},
    {"question": "Há»c phÃ­ lÃ  bao nhiÃªu?", "answer": "Há»c phÃ­ khÃ¡c nhau tÃ¹y theo chÆ°Æ¡ng trÃ¬nh. Vui lÃ²ng truy cáº­p trang há»c phÃ­ cá»§a chÃºng tÃ´i Ä‘á»ƒ biáº¿t chi tiáº¿t."},
    {"question": "LÃ m tháº¿ nÃ o Ä‘á»ƒ tÃ´i Ä‘Äƒng kÃ½ há»c bá»•ng?", "answer": "Há»c bá»•ng cÃ³ sáºµn cho nhá»¯ng sinh viÃªn Ä‘á»§ Ä‘iá»u kiá»‡n. HÃ£y kiá»ƒm tra trang há»c bá»•ng cá»§a chÃºng tÃ´i Ä‘á»ƒ biáº¿t thÃ´ng tin chi tiáº¿t."},
    {"question": "Thá»i háº¡n ná»™p Ä‘Æ¡n lÃ  khi nÃ o?", "answer": "Thá»i háº¡n ná»™p Ä‘Æ¡n khÃ¡c nhau tÃ¹y theo chÆ°Æ¡ng trÃ¬nh vÃ  Ä‘á»£t tuyá»ƒn sinh. Vui lÃ²ng kiá»ƒm tra trang tuyá»ƒn sinh Ä‘á»ƒ biáº¿t ngÃ y cá»¥ thá»ƒ."}
]

# Convert FAQ questions to embeddings
faq_questions = [item["question"] for item in faq_data]
faq_embeddings = sbert_model.encode(faq_questions, convert_to_tensor=True).cpu().numpy()

# Build FAISS index
faiss_index = faiss.IndexFlatL2(faq_embeddings.shape[1])
faiss_index.add(faq_embeddings)

# Function to find best match using SBERT
def find_best_match(user_query):
    query_embedding = sbert_model.encode([user_query], convert_to_tensor=True).cpu().numpy()
    _, best_match_idx = faiss_index.search(query_embedding, 1)
    best_match = faq_data[best_match_idx[0][0]]
    # Compute similarity
    best_match_embedding = faq_embeddings[best_match_idx[0][0]]
    similarity = util.cos_sim(query_embedding, best_match_embedding).item()
    return best_match, similarity
    #return faq_data[best_match_idx[0][0]]

# Function to generate GPT-4 response
def generate_gpt4_response(question, context):
    prompt = (
        f"Má»™t sinh viÃªn há»i: {question}\n\n"
        f"Dá»±a trÃªn thÃ´ng tin tÃ¬m Ä‘Æ°á»£c trÃªn internett, hÃ£y cung cáº¥p má»™t cÃ¢u tráº£ lá»i há»¯u Ã­ch, ngáº¯n gá»n vÃ  thÃ¢n thiá»‡n. Dáº«n nguá»“n náº¿u cÃ³ thá»ƒ."
    )
    
    try:
        response = client.chat.completions.create(  # FIXED API CALL
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Báº¡n lÃ  má»™t trá»£ lÃ½ tuyá»ƒn sinh Ä‘áº¡i há»c há»¯u Ã­ch."},
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âš ï¸ Lá»—i: {str(e)}"

# Streamlit UI
st.title("ğŸ“ Há»— trá»£ tÆ° váº¥n tuyá»ƒn sinh - ÄHCNGTVT")
st.write("Há»i tÃ´i báº¥t ká»³ Ä‘iá»u gÃ¬ vá» tuyá»ƒn sinh Ä‘áº¡i há»c!")

user_input = st.text_input("Nháº­p cÃ¢u há»i cá»§a báº¡n:")

if user_input:
    best_match, similarity = find_best_match(user_input)
    threshold = 0.7  # Define a similarity threshold
    if similarity >= threshold:
        final_response = best_match["answer"]
        use_gpt = False
    else:
        final_response = generate_gpt4_response(user_input, best_match["answer"])
        use_gpt = True

    st.subheader("ğŸ¤– Pháº£n há»“i tá»« chatbot")
    st.write(final_response)

    st.subheader("ğŸ“Œ CÃ¢u há»i khá»›p FAQ")
    st.write(f"**Q:** {best_match['question']}")
    st.write(f"**A:** {best_match['answer']}")

    # Show similarity score for debugging purposes (optional)
    st.write(f"ğŸ” **Äá»™ tÆ°Æ¡ng Ä‘á»“ng:** {similarity:.2f}")

    if use_gpt:
        st.warning("ğŸ“¢ GPT-4 Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng vÃ¬ cÃ¢u tráº£ lá»i tá»« FAQ khÃ´ng Ä‘á»§ chÃ­nh xÃ¡c.")

